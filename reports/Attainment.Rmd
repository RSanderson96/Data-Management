---
title: "A Consideration of Attainment"
author: "Rachael Sanderson"
date: "5 November 2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
library(ProjectTemplate)

```

```{r load_project, include = FALSE}
load.project()

```

So far, this analysis has focused purely on understanding and plotting the trend of how many people fail to complete the course. However, when considering the rate of individuals leaving the course, it does not consider the attainment of the individuals that remain in the course, which is the main way that programme's success is measured. This section will deliberately focus on this aspect, with a particular emphasis on the impact of specific teaching methods - videos - on the attainment of these individuals.

#Measuring Attainment

##*Selected Data*
The data set for this section of analysis was selected as a measure of student skill or ability within the course. Within the available data, there is an overview of how each participant scored on the 'quiz' questions during specific steps of the course, hence showing the knowledge of students in the form of correct or incorrect multiple choice answers. The data contains individual learner IDs, question completed, question type, step number, answer given, whethere it was correct and a time stamp. The quiz steps are identical in each or the 7 runs of the course, making this data comparable, whilst also being the only indicator of understanding provided within the dataset. The main indicator used in this section was how many times each question was answered correctly.

##*Preparing the data*
A data frame was produced to show how many people answered each question correctly for each step, each course run.

```{R QuestionsDF}

Questions.function = function(x){ #x = file selected to analyse
  
  Questions = x
  Q= unique(Questions$quiz_question, incomparables = FALSE) 
                #list the unique questions
  L =length(Q)  #How many questions are there?
  
  Response_Correct = vector() #making the vestor
  for(i in 1:L){ #for loop: L = how many questions will be assessed/length of vector
    Asked = Questions %>% filter (quiz_question == Q[i]) 
                 #how many people answered each question
    True = Asked %>% filter (correct == "true")
                 #how many people answered the question correctly
    T = nrow (True)
    S = nrow (Asked)
  Response_Correct[i] = (T/S)}  
                 #provided percentage of correct answers for each question
  return(Response_Correct)
  }
  
```

The final data frame shows the average number of correct answers over the run of the course, and breaks this down into individual course runs

```{R ShowDF, include = FALSE}
CorrectDF 

```

##*Visualising the Data*

The initial approach was to model as a scatter plot; 

```{R Questions_Scatter, echo = FALSE, fig.width=12, fig.height = 8}
Correct = ggplot(data=CorrectDF, x=Question, Y = Correct_Answers)
C1 = Correct + geom_point(aes(x=Question, y=Course1, colour = "Course1"))
C2 = C1 + geom_point(aes(x=Question, y=Course2, colour = "Course2"))
C3 = C2 + geom_point(aes(x=Question, y=Course3, colour = "Course3"))
C4 = C3 + geom_point(aes(x=Question, y=Course4, colour = "Course4"))
C5 = C4 + geom_point(aes(x=Question, y=Course5, colour = "Course5"))
C6 = C5 + geom_point(aes(x=Question, y=Course6, colour = "Course6"))
C7 = C6 + geom_point(aes(x=Question, y=Course7, colour = "Course7"))
C8 = C7 +labs(title="The Number of Correct Answers for Each Question",
        x ="Question", y = "Number of Correct Answers")

C8
```

This plot is useful to see variations within a question, for example the first run of the course show different scores compared to other runs (2.19.1 - 3.11.3). To identify a single question, and reflect an in depth level of data, this is a useful model. However, when considering the courses overall, the chart is very busy, making it hard to see the overall attainment for a single course. 

The alternative visualisation is a collection of boxplots:

```{R Question_Box, fig.width=12}
Correct = within(CorrectDF, rm(Question, Average))
CorrectVec = as.vector(as.matrix(Correct))
Course = rep(1:7, each = 22)
BoxDF = data.frame(Course = Course, Score = CorrectVec)

Box = ggplot(data = BoxDF, x = Course, y = Score)
B1 = Box + geom_boxplot(aes(group = Course, x = Course, y = Score, fill = factor(Course)))
B2 = B1 + labs(title="The Average Number of Correct Answers Throughout a Course Run",
        x ="Course", y = "Percentage of Correct Answers (%)")

B2
```

This is useful to reflect the overall attainment for all questions within a course. The medians are all relatively similar, particularly when outliers are acknowledged. The majority are mostly skewed to the lower end of the scores (shown by the smaller second lower quartile); this is increasingly more so after course 2. The split between runs 2 and 3 is important: this is the point when videos were introduced. 

#The Impact of Videos

Since the third cycle of the course, videos have been used as an educational method. The data collected has considered the video duration, total views, viewing method and viewer location amongst other factors. It is important to reflect on the use of this method, and whether there is a high uptake by students to make them a worthwhile educational tool. Awareness of this information has potential to inform whether videos are a worthwhile investment as an educational method, and so whether the use of them should be increased or decreased.

##*The Video Dataset*
Initially, the data was considered through 5 datasets, for each run of the course that used videos. The Video data itself is a strong dataset, with responses or quantities for all categories investigated.
The final dataset was constructed within a dataframe. Each column was selected from their respective datasets, then pulled together into a single object, with additional average and duration columns to support the analysis. 

``` {R Views_Dataframe_Construction}
StepPosition = Video3$step_position #seperating columns for vectors
V3Views = Video3$total_views
V4Views = Video4$total_views
V5Views = Video5$total_views
V6Views = Video6$total_views
V7Views = Video7$total_views
Average = (V3Views +V4Views +V5Views +V6Views +V7Views)/5 #average over the runs

#Linking the columns together within a single dataframe
DFViews = data.frame (Step = StepPosition, Video3 = V3Views, Video4 = V4Views, Video5 = V5Views,Video6 = V6Views,Video7 = V7Views, Mean = Average)
```

This dataframe allowed a clear comparison across the datasets, to inform the temporal analysis of the use of videos within the educational course. the final product can be seen below:

``` {R Views_Dataframe, echo = FALSE}
DFViews

```

##*The Findings*

###*Are people using Video?: Raw Data*

The final analysis produced a ggplot of each layer, to visualise how use of the video platform has changed over time. 
```{R Scatter}
Graph=ggplot (data = DFViews, aes (x = Step, y= Total.Video.Views))
g3 = Graph + geom_point(aes(x = Step, y=V3Views, colour = "Course Run 3")) #adding each course run
g4 = g3+ geom_point (aes (x=Step, y=V4Views, colour = "Course Run 4"))
g5 = g4+ geom_point (aes (x=Step, y=V5Views, colour = "Course Run 5")) 
g6 = g5+ geom_point (aes (x=Step, y=V6Views, colour = "Course Run 6"))
g7= g6+ geom_point (aes (x=Step, y=V7Views, colour = "Course Run 7"))

g8 = g7 + geom_line (aes(x=Step, y=Mean, colour = "Average Views")) #adding the average line
g9 = g8 +labs(title="Total Viewings of each Video",
        x ="Video Step", y = "Total Views")
g9
```

An alternative model was to visualise as a line chart from a similar process, using geom_line instead of geom_point;

```{R Line, echo = FALSE}
Line=ggplot (data = DFViews, aes (x = Step, y= V3Views))
L3 = Line + geom_line(aes(x = Step, y=V3Views, colour = "Course Run 3")) #adding each run
L4 = L3+ geom_line (aes (x=Step, y=V4Views, colour = "Course Run 4"))
L5 = L4+ geom_line (aes (x=Step, y=V5Views, colour = "Course Run 5")) 
L6 = L5+ geom_line (aes (x=Step, y=V6Views, colour = "Course Run 6"))
L7= L6+ geom_line (aes (x=Step, y=V7Views, colour = "Course Run 7"))
L8 = L7 + geom_line (aes(x=Step, y= Mean, colour = "Average Views")) #adding the average line
L9 = L8 +labs(title="Total Viewings of each Video",
        x ="Video Step", y = "Total Views")
L9

```

Whilst this is a usful visual, the scatter is clearer to interpret, especially when the Average line is applied as a comparison. 

###*Are people using Video?: Proportions*

An alternative is to apply the same graphical model, but as a proportion of people that started each step, as the rate of viewers will always decrease as people drop out of the course.  Therefore, each Y value was divided by the number of people that started that specific step (from the step activity data, reviewed in the previous run), to produce the following graph;

```{R Proportion, echo = FALSE}

Line=ggplot (data = DFViewsProportion, aes (x = Step, y= Video3)) #initial line coordinates

L3 = Line + geom_point(aes(x = Step, y=Video3, colour = "Course Run 3")) #adding each run
L4 = L3+ geom_point (aes (x=Step, y=Video4, colour = "Course Run 4"))
L5 = L4+ geom_point (aes (x=Step, y=Video5, colour = "Course Run 5")) 
L6 = L5+ geom_point (aes (x=Step, y=Video6, colour = "Course Run 6"))
L7= L6 + geom_point (aes (x=Step, y=Video7, colour = "Course Run 7"))
L8 = L7 + geom_line (aes ( x=Step, y=DFViewsProportion$Average, colour = "Average"))

L8

#ADD LINES  - THE LOW X VALUES, AND THE AVERAGE Y VALUE 
#*OR
#LINES FOR WHEN THE QUESTIONS ARE

```

Within this graph, the preferred scatter style was maintained, as it had already been observed to be a clearer model. The use of proportion allows two things to be visible. Firstly, which videos are 'dips' in the number of people that answer them. Whilst the Videos are not representative for student application to every step, they show clear peaks and troughs that could be investigated further. Additionally, the repetitive returning point of the average line to the region of 80 - 90% reflects the standard engagement of the individuals that have started the specific video step. 

#Comparing The Use of Videos to Overall Scores

##*Timescales: Videos and Questions

An element of interest was if videos had higher views if they were near a quiz, for example if students used them as a revision tool to answer questions. This was modelled in the graph below:

```{R Question_Lines, echo = FALSE}
 StepActivity = cyber.security.7.question.response
Questions = unique(StepActivity$quiz_question, incomparables = FALSE)
  
Steps=c((StepActivity$week_number)+((StepActivity$step_number)/100)) #acknowledging data complication
  StepActivity = cbind(StepActivity, Steps) #editing the data with the new column
  S= unique(StepActivity$Steps, incomparables = FALSE) #list the unique steps
  
Q9 = L8 + geom_vline(xintercept = (S[1]), (aes (colour = "red")))
Q10 = Q9 + geom_vline(xintercept = (S[2]), (aes (colour = "red")))
Q11 = Q10 + geom_vline(xintercept = (S[3]), (aes (color = "red")))
Q12 = Q11 + geom_vline(xintercept = (S[4]), (aes (color = "red")))
Q13 = Q12 + geom_vline(xintercept = (S[5]), (aes (color = "red")))

Q13

```

Arguably there is limited impact of the quiz timings on the number of views. Whilst this does not infer anything about the value of videos as a teaching method, it does imply that the amount of video usage is not impacted by the presence of a quiz. 

##*Did Videos change the level of attainment?*
An alternative assessment of the impact of videos is to perform a hypothesis test to consider if the average number of correct test scores for a course run was affected by the presence of videos. 

The decision was made to compare the proportion of correct quiz responses for each learner. Counting the number of correct answers ignores the individuals that only attempted a limited number of questions. Additionally, the number of attempts is also varied - this suggests an anomoly within the data that could be investigated further, although is beyond the limits of this specific exploration. Therefore, proportion of correct attempts was the preferred method of analysis; this way the flaws of the data set can be limited by only focusing on the attempts observed.

The percentages were calculated as below;

```{R Results.function}

Results.function = function(y){
Answers= y %>% filter(correct == "true") %>% count(learner_id) %>% arrange(-n)
#how many correct answers for each learner ID?
Attempts =y %>% count(learner_id) %>% arrange(-n)
#How many attempts for each learner ID?
Results = merge(Answers, Attempts, by = "learner_id", all = TRUE)
Results = Results[rowSums(is.na(Results)) == 0,]
Results = Results%>% rename(Answers = n.x, Attempts = n.y )
Score = ((Results$Answers)/(Results$Attempts)*100)
Results = cbind(Results, Score)
Results = Results[-c(1), ]
return(Results)}

```

These scores can hence be used in the following hypothesis test, to reflect whether the years after the introduction of video showed higher attainment than the years beforehand

Therefore the hypotheses for testing were as follows- 
  Ho: Average Score for course run 2 = Average score for each other course
  H1: Average Score for course run 2 != Average score for each other course

All courses had a sample size of larger than 30, so the Central Limit Theorem could be applied.

From these scores, the average, standard deviation and sample sizes were calculated;

```{R ResultsDF, echo = FALSE}
Resultsdf

```

And the following P Values:

```{R P_Values, echo = FALSE}
Pvalues

```

Testing at a 95% value, Runs 3, 5, 6, 7 do not have a significantly different average score compared to run 2. Therefore, there is insufficient evidence that the introduction of video has changed the attainment of the pupils, when these runs are evaluated.

Comparatively, Run 4 has a significantly lower average at this test level, implying that there is sufficient evidence at a 95% level to suggest that this run has a *lower* mean than Run 2. This reinforces the evidence that video does not improve attainment. However, as a single run in comparison to the other 4, it is less persuasive to suggest that videos overall cause lower attainment. This is something that would need to be evaluated within further runs of the course.


##*Limits to the dataset*
When considering the impact of teaching methods and engagement, this dataset has strong limitations. Whilst the question data can be associated with a learning ID, the video data is not; consequentially, all data is very generalised. Therefore, dependencies cannot be directly linked, as it cannot be tested if people watched videos AND answered correctly, as a direct Hypothesis test. 



