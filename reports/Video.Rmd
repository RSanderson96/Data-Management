---
title: "A Consideration of Attainment"
author: "Rachael Sanderson"
date: "5 November 2019"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
library(ProjectTemplate)

```

```{r load_project, include = FALSE}
load.project()

```

So far, this analysis has focused purely on plotting the trend of 'dropping out'. However, when considering the rate of individuals leaving the course, it does not consider the attainment of the individuals that remain in the course. This section will deliberately focus on this aspect, with a particular emphasis on the impact of taching methods (specifically videos) on the attainment of these individuals.

##*Measuring Attainment*

#*The Data Used*
Within the data supplied, there is an overview of how each participant scored on the 'quiz' questions during specific steps of the course. The quiz steps are identical in each or the 7 runs of the course, making this data comparable, whilst also being the only indicator of understanding provided within the dataset. 

#*Preparing the data*
Once again, a data frame was produced, this time showing how many people answered each question correctly for each step, each course run.

```{R QuestionsDF}
Q = unique(cyber.security.1.question.response$quiz_question,incomparables = FALSE)
Questions.function = function(x){ #x = file selected to analyse
  
  Questions = x
  Q= unique(Questions$quiz_question, incomparables = FALSE) #list the unique questions
  L =length(Q) #How many questions are there?
  
  Response_Correct = vector() #making the vestor
  for(i in 1:L){ #for loop: L = how many questions will be assessed/length of vector
    Asked = Questions %>% filter (quiz_question == Q[i]) 
                                    #how many people answered each question
    True = Asked %>% filter (correct == "true")
                                    #how many people answered the question correctly
    T = nrow (True)
    S = nrow (Asked)
  Response_Correct[i] = (T/S)}  
                                    #provided percentage of correct answers for each question
  return(Response_Correct)
  }
  
```

The final data frame shows the average number of correct answers over the run of the course, and breaks this down into individual course runs

```{R ShowDF, include = FALSE}
CorrectDF 

```

This data can then be visualised as below;

The initial approach was to model as a scatter plot; 

```{R Questions_Scatter, echo = FALSE}
Correct = ggplot(data=CorrectDF, x=Question, Y = Correct_Answers)
C1 = Correct + geom_point(aes(x=Question, y=Course1, colour = "Course1"))
C2 = C1 + geom_point(aes(x=Question, y=Course2, colour = "Course2"))
C3 = C2 + geom_point(aes(x=Question, y=Course3, colour = "Course3"))
C4 = C3 + geom_point(aes(x=Question, y=Course4, colour = "Course4"))
C5 = C4 + geom_point(aes(x=Question, y=Course5, colour = "Course5"))
C6 = C5 + geom_point(aes(x=Question, y=Course6, colour = "Course6"))
C7 = C6 + geom_point(aes(x=Question, y=Course7, colour = "Course7"))

C7
```

This plot is useful to see variations within a question, for example the first run of the course show different scores compared to other runs (2.19.1 - 3.11.3). However, when considering the courses overall, the chart is very busy, making it hard to see the overall attainment for a single course. However, to identify a single question, and reflect a lower level of data, this is still a useful model.

The alternative visualisation is a collection of boxplots:

```{R Question_Box}
boxplot(CorrectDF$Course1, CorrectDF$Course2, CorrectDF$Course3, CorrectDF$Course4, CorrectDF$Course5, CorrectDF$Course6, CorrectDF$Course7,
        main = "Comparison of the results for each course",
        names = c("Course 1", "Course 2", "Course3", "Course 4", "Course 5", "Course 6", "Course 7"),
        ylab = "% Correct Responses",
        xlab = "Course Run")

```

This is useful to reflect the overall attainment for all questions within a course. The medians are all relatively similar, particularly when outliers are acknowledged. The majority are mostly skewed to the lower end of the scores (shown by the smaller second lower quartile); this is increasingly more so after course 2. The split between runs 2 and 3 is important: this is the point when videos were introduced. 

##*The Impact of Videos?*

Since the third cycle of the course, videos have been used as an educational method. The data collected has considered the video duration, total views, viewing method and viewer location amongst other factors. It is important to reflect on the use of this method, and whether there is a high uptake by students to make them a worthwhile educational tool. Awareness of this information has potential to inform whether videos are a worthwhile investment as an educational method, and so whether the use of them should be increased or decreased.

##*The Video Data*
Initially, the data was considered through 5 datasets, for each run of the course that used videos. The Video data itself is a strong dataset, with responses or quantities for all categories investigated.
The final dataset was constructed within a dataframe. Each column was selected from their respective datasets, then pulled together into a single object, with additional average and duration columns to support the analysis. 

``` {R Views_Dataframe_Construction}
#creating each column
StepPosition = Video3$step_position #seperating columns for vectors
V3Views = Video3$total_views
V4Views = Video4$total_views
V5Views = Video5$total_views
V6Views = Video6$total_views
V7Views = Video7$total_views
Average = (V3Views +V4Views +V5Views +V6Views +V7Views)/5 #average over the runs

#Linking the columns together within a single dataframe
DFViews = data.frame (Step = StepPosition, Video3 = V3Views, Video4 = V4Views, Video5 = V5Views,Video6 = V6Views,Video7 = V7Views, 
                      Duration = Video3$video_duration, Mean = Average)
```

This dataframe allowed a clear comparison across the datasets, to inform the temporal analysis of the use of videos within the educational course. the final product can be seen below:

``` {R Views_Dataframe, echo = FALSE}
DFViews

```

##* The Findings*

###*Are people using Video?*

The final analysis produced a ggplot of each layer, to visualise how use of the video platform has changed over time. 
```{R Scatter}
Graph=ggplot (data = DFViews, aes (x = Step, y= Total.Video.Views))
g3 = Graph + geom_point(aes(x = Step, y=V3Views, colour = "Course Run 3")) #adding each course run
g4 = g3+ geom_point (aes (x=Step, y=V4Views, colour = "Course Run 4"))
g5 = g4+ geom_point (aes (x=Step, y=V5Views, colour = "Course Run 5")) 
g6 = g5+ geom_point (aes (x=Step, y=V6Views, colour = "Course Run 6"))
g7= g6+ geom_point (aes (x=Step, y=V7Views, colour = "Course Run 7"))

g8 = g7 + geom_line (aes(x=Step, y=Mean, colour = "Average Views")) #adding the average line
g9 = g8 +labs(title="Total Viewings of each Video",
        x ="Video Step", y = "Total Views")
g8
```

This could also be visualised as a line chart from a similar process, using geom_line instead of geom_point;

```{R Line, echo = FALSE}
Line=ggplot (data = DFViews, aes (x = Step, y= V3Views))
L3 = Line + geom_line(aes(x = Step, y=V3Views, colour = "Course Run 3")) #adding each run
L4 = L3+ geom_line (aes (x=Step, y=V4Views, colour = "Course Run 4"))
L5 = L4+ geom_line (aes (x=Step, y=V5Views, colour = "Course Run 5")) 
L6 = L5+ geom_line (aes (x=Step, y=V6Views, colour = "Course Run 6"))
L7= L6+ geom_line (aes (x=Step, y=V7Views, colour = "Course Run 7"))
L8 = L7 + geom_line (aes(x=Step, y= Mean, colour = "Average Views")) #adding the average line
L8 #test

```
Alternatively, a proportional representation acknowledges the number of people who were accepted at the start of each course, to provide context to the changes;

```{R Proportion}
DFViewsProportion = data.frame (Step = StepPosition, Video3 = (V3Views/(Cohort_Summaries$Entries[3])), Video4 = V4Views/ (Cohort_Summaries$Entries[4]), Video5 = V5Views/(Cohort_Summaries$Entries[5]),Video6 = V6Views/(Cohort_Summaries$Entries[6]),Video7 = V7Views/(Cohort_Summaries$Entries[7]), 
                      Duration = Video3$video_duration)

Line=ggplot (data = DFViewsProportion, aes (x = Step, y= Video3)) #initial line coordinates

L3 = Line + geom_line(aes(x = Step, y=Video3, colour = "Course Run 3")) #adding each run
L4 = L3+ geom_line (aes (x=Step, y=Video4, colour = "Course Run 4"))
L5 = L4+ geom_line (aes (x=Step, y=Video5, colour = "Course Run 5")) 
L6 = L5+ geom_line (aes (x=Step, y=Video6, colour = "Course Run 6"))
L7= L6+ geom_line (aes (x=Step, y=Video7, colour = "Course Run 7"))

L7

```


