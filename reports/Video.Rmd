---
title: "A Consideration of Attainment"
author: "Rachael Sanderson"
date: "5 November 2019"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
library(ProjectTemplate)

```

```{r load_project, include = FALSE}
load.project()

```

So far, this analysis has focused purely on understanding and plotting the trend of how many people fail to complete the course. However, when considering the rate of individuals leaving the course, it does not consider the attainment of the individuals that remain in the course, which is the main way the the success of the course is measured. This section will deliberately focus on this aspect, with a particular emphasis on the impact of teaching methods (specifically videos) on the attainment of these individuals.

#Measuring Attainment

##*Selected Data*
The data set for this section of analysis was selected as a measure of student skill or ability within the course. Within the available data, there is an overview of how each participant scored on the 'quiz' questions during specific steps of the course, hence showing the knowledge of students in the form of correct or incorrect multiple choice answers. The data contains individual learner IDs, question completed, question type, step number, answer given, whethere it was correct and a time stamp. The quiz steps are identical in each or the 7 runs of the course, making this data comparable, whilst also being the only indicator of understanding provided within the dataset. The main indicator used in this section was how many times each question was answered correctly.

##*Preparing the data*
Once again, a data frame was produced, this time showing how many people answered each question correctly for each step, each course run.

```{R QuestionsDF}

Questions.function = function(x){ #x = file selected to analyse
  
  Questions = x
  Q= unique(Questions$quiz_question, incomparables = FALSE) 
                #list the unique questions
  L =length(Q)  #How many questions are there?
  
  Response_Correct = vector() #making the vestor
  for(i in 1:L){ #for loop: L = how many questions will be assessed/length of vector
    Asked = Questions %>% filter (quiz_question == Q[i]) 
                 #how many people answered each question
    True = Asked %>% filter (correct == "true")
                 #how many people answered the question correctly
    T = nrow (True)
    S = nrow (Asked)
  Response_Correct[i] = (T/S)}  
                 #provided percentage of correct answers for each question
  return(Response_Correct)
  }
  
```

The final data frame shows the average number of correct answers over the run of the course, and breaks this down into individual course runs

```{R ShowDF, echo = FALSE}
CorrectDF 

```

##*Visualising the Data*

The initial approach was to model as a scatter plot; 

```{R Questions_Scatter, echo = FALSE}
Correct = ggplot(data=CorrectDF, x=Question, Y = Correct_Answers)
C1 = Correct + geom_point(aes(x=Question, y=Course1, colour = "Course1"))
C2 = C1 + geom_point(aes(x=Question, y=Course2, colour = "Course2"))
C3 = C2 + geom_point(aes(x=Question, y=Course3, colour = "Course3"))
C4 = C3 + geom_point(aes(x=Question, y=Course4, colour = "Course4"))
C5 = C4 + geom_point(aes(x=Question, y=Course5, colour = "Course5"))
C6 = C5 + geom_point(aes(x=Question, y=Course6, colour = "Course6"))
C7 = C6 + geom_point(aes(x=Question, y=Course7, colour = "Course7"))
C8 = C7 +labs(title="The Number of Correct Answers for Each Question",
        x ="Question", y = "Number of Correct Answers")

C8
```

This plot is useful to see variations within a question, for example the first run of the course show different scores compared to other runs (2.19.1 - 3.11.3). To identify a single question, and reflect an in depth level of data, this is a useful model. However, when considering the courses overall, the chart is very busy, making it hard to see the overall attainment for a single course. 

The alternative visualisation is a collection of boxplots:

```{R Question_Box}
boxplot(CorrectDF$Course1, CorrectDF$Course2, CorrectDF$Course3, CorrectDF$Course4, CorrectDF$Course5, CorrectDF$Course6, CorrectDF$Course7,
        main = "Comparison of the results for each course",
        names = c("Course 1", "Course 2", "Course3", "Course 4", "Course 5", "Course 6", "Course 7"),
        ylab = "% Correct Responses",
        xlab = "Course Run")

```

This is useful to reflect the overall attainment for all questions within a course. The medians are all relatively similar, particularly when outliers are acknowledged. The majority are mostly skewed to the lower end of the scores (shown by the smaller second lower quartile); this is increasingly more so after course 2. The split between runs 2 and 3 is important: this is the point when videos were introduced. 

#The Impact of Videos

Since the third cycle of the course, videos have been used as an educational method. The data collected has considered the video duration, total views, viewing method and viewer location amongst other factors. It is important to reflect on the use of this method, and whether there is a high uptake by students to make them a worthwhile educational tool. Awareness of this information has potential to inform whether videos are a worthwhile investment as an educational method, and so whether the use of them should be increased or decreased.

##*The Video Dataset*
Initially, the data was considered through 5 datasets, for each run of the course that used videos. The Video data itself is a strong dataset, with responses or quantities for all categories investigated.
The final dataset was constructed within a dataframe. Each column was selected from their respective datasets, then pulled together into a single object, with additional average and duration columns to support the analysis. 

``` {R Views_Dataframe_Construction}
StepPosition = Video3$step_position #seperating columns for vectors
V3Views = Video3$total_views
V4Views = Video4$total_views
V5Views = Video5$total_views
V6Views = Video6$total_views
V7Views = Video7$total_views
Average = (V3Views +V4Views +V5Views +V6Views +V7Views)/5 #average over the runs

#Linking the columns together within a single dataframe
DFViews = data.frame (Step = StepPosition, Video3 = V3Views, Video4 = V4Views, Video5 = V5Views,Video6 = V6Views,Video7 = V7Views, Mean = Average)
```

This dataframe allowed a clear comparison across the datasets, to inform the temporal analysis of the use of videos within the educational course. the final product can be seen below:

``` {R Views_Dataframe, echo = FALSE}
DFViews

```

##*The Findings*

###*Are people using Video?: Raw Data*

The final analysis produced a ggplot of each layer, to visualise how use of the video platform has changed over time. 
```{R Scatter}
Graph=ggplot (data = DFViews, aes (x = Step, y= Total.Video.Views))
g3 = Graph + geom_point(aes(x = Step, y=V3Views, colour = "Course Run 3")) #adding each course run
g4 = g3+ geom_point (aes (x=Step, y=V4Views, colour = "Course Run 4"))
g5 = g4+ geom_point (aes (x=Step, y=V5Views, colour = "Course Run 5")) 
g6 = g5+ geom_point (aes (x=Step, y=V6Views, colour = "Course Run 6"))
g7= g6+ geom_point (aes (x=Step, y=V7Views, colour = "Course Run 7"))

g8 = g7 + geom_line (aes(x=Step, y=Mean, colour = "Average Views")) #adding the average line
g9 = g8 +labs(title="Total Viewings of each Video",
        x ="Video Step", y = "Total Views")
g9
```

An alternative model was to visualise as a line chart from a similar process, using geom_line instead of geom_point;

```{R Line, echo = FALSE}
Line=ggplot (data = DFViews, aes (x = Step, y= V3Views))
L3 = Line + geom_line(aes(x = Step, y=V3Views, colour = "Course Run 3")) #adding each run
L4 = L3+ geom_line (aes (x=Step, y=V4Views, colour = "Course Run 4"))
L5 = L4+ geom_line (aes (x=Step, y=V5Views, colour = "Course Run 5")) 
L6 = L5+ geom_line (aes (x=Step, y=V6Views, colour = "Course Run 6"))
L7= L6+ geom_line (aes (x=Step, y=V7Views, colour = "Course Run 7"))
L8 = L7 + geom_line (aes(x=Step, y= Mean, colour = "Average Views")) #adding the average line
L9 = L8 +labs(title="Total Viewings of each Video",
        x ="Video Step", y = "Total Views")
L9

```
Whilst this is a usful visual, the scatter is clearer to interpret, especially when the Average line is applied as a comparison. 

###*Are people using Video?: Proportions*

An alternative is to apply the same graphical model, but as a proportion of people that started each step, as the rate of viewers will always decrease as people drop out of the course.  Therefore, each Y value was divided by the number of people that started that specific step, to produce the following graph;

```{R Proportion, echo = FALSE}

Line=ggplot (data = DFViewsProportion, aes (x = Step, y= Video3)) #initial line coordinates

L3 = Line + geom_point(aes(x = Step, y=Video3, colour = "Course Run 3")) #adding each run
L4 = L3+ geom_point (aes (x=Step, y=Video4, colour = "Course Run 4"))
L5 = L4+ geom_point (aes (x=Step, y=Video5, colour = "Course Run 5")) 
L6 = L5+ geom_point (aes (x=Step, y=Video6, colour = "Course Run 6"))
L7= L6 + geom_point (aes (x=Step, y=Video7, colour = "Course Run 7"))
L8 = L7 + geom_line (aes ( x=Step, y=DFViewsProportion$Average, colour = "Average"))

L8

#ADD LINES  - THE LOW X VALUES, AND THE AVERAGE Y VALUE 
#*OR
#LINES FOR WHEN THE QUESTIONS ARE

```

Within this graph, the preferred scatter style was maintained, as it had already been observed to be a clearer model. The use of proportion allows two things to be visible. Firstly, which videos are 'dips' in the number of people that answer them. Whilst the Videos are not representative for student application to every step, they show clear peaks and troughs that could be investigated further. Additionally, the repetitive returning point of the average line to the region of 80 - 90% reflects the standard engagement of the individuals that have started the specific video step. 

#Comparing The Use of Videos to Overall Scores

##*Timescales: Videos and Questions
ADD X LINES TO THE VIDEO PROPORTION GRAPH.

##*Did Videos change the level of attainment?*
Hypothesis test: Mean score for Course 2 vs Mean Score for Course 3/Course 7

##*Limits to the dataset*
When considering the impact of teaching methods and engagement, this dataset has strong limitations. Whilst the question data can be associated with a learning ID, the video data is not; consequentially, all data is very generalised. Therefore, dependencies cannot be directly linked, as it cannot be tested if people watched videos AND answered correctly, as a direct Hypothesis test. 

DO people complete the quiz stages?
DO people complete the video stages?


